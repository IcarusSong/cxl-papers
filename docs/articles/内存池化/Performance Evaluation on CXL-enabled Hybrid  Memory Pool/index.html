<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
        Document
    </title>
    <link rel='stylesheet' href=../../../css/index.css />
    
    <link rel="icon" href="https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png">
</head>

<body class="light">
    <a href="https://github.com/IcarusSong/cxl-papers.git" target="_blank" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <div class="header-navigator"><ul><li><a href="#h1-0">Performance Evaluation on CXL-enabled Hybrid  Memory Pool</a><ul><li><a href="#h2-1">1. 文章背景</a></li></ul><ul><li><a href="#h2-2">2. 相关工作以及局限性</a></li></ul><ul><li><a href="#h2-3">3. 论文发现以及论文贡献</a></li></ul><ul><li><a href="#h2-4">4. 方法策略</a></li></ul><ul><li><a href="#h2-5">5. 实验设置与实验结果</a></li></ul><ul><li><a href="#h2-6">6. 前提假设与局限性</a></li></ul></li></ul></div><div class='markdown-body'><h1 id="h1-0">Performance Evaluation on CXL-enabled Hybrid  Memory Pool</h1><h2 id="h2-1"><ol start="1"><li>文章背景</li></ol></h2><p>随着深度学习训练、大数据处理以及内存数据库等现代化应用的发展，对内存的需求日益增长，常常超出单台机器的内存容量。研究表明，在谷歌和阿里巴巴等公有云供应商中，有高达一半的内存硬件资源未被充分利用。为了解决资源利用率低和成本高的问题，内存池化（Memory Disaggregation）方案被提出，它将内存资源从服务器中分离出来，进行统一管理和扩展。</p><p>新兴的 Compute Express Link (CXL) 互连技术提供了一种高速缓存一致性的连接方式，允许 CPU 以接近 DRAM 的延迟访问池化内存，成为实现内存池化的一个极具前景的方案。然而，即便实现了内存池化，DRAM 本身仍然是云服务器成本的主要部分，约占服务器成本的一半，且功耗远高于 SSD。因此，本文研究将成本更低、功耗更小的 NVMe SSD 引入到 CXL 内存池中，构建 DRAM-SSD 混合内存池，以期在不牺牲应用性能的前提下进一步降低云服务器的成本。</p><h2 id="h2-2"><ol start="2"><li>相关工作以及局限性</li></ol></h2><p><b>相关工作</b></p><ul><li><b>基于 RDMA 的内存池化</b>：在 CXL 出现之前，研究者们提出了基于远程直接内存访问（RDMA）的方案。RDMA 通过内核旁路和零拷贝技术提供高吞吐和低延迟的内存访问。</li></ul><ul><li><b>其他缓存一致性互连技术</b>：除 CXL 外，还有 NVLink、Gen-Z 和 OpenCAPI 等其他缓存一致性解决方案。</li></ul><ul><li><b>基于 CXL 的内存管理</b>：Li 等人利用机器学习预测器来分配虚拟机在本地和 CXL 内存池中的内存，以达到可容忍的性能下降。TMO 则通过监控性能下降，动态地将应用的冷数据页卸载到更便宜的存储介质上。</li></ul><ul><li><b>基于 FPGA 的原型</b>：近期有研究提出了基于 FPGA 的 CXL 内存池化原型，如 DirectCXL 和 ThymesisFlow，这些研究表明通过结合本地和远程内存池，一些应用的性能几乎没有衰减。</li></ul><p><b>局限性</b></p><ul><li><b>RDMA 的局限性</b>：RDMA 并非缓存一致性的，当缓存满时，其访问延迟会远高于本地 DRAM，并且仍有传统 DMA 式数据传输的开销，因此未被部署在对性能要求苛刻的云环境中。</li></ul><ul><li><b>现有研究的空白</b>：作者指出，现有的工作没有研究过多层级、多介质（如 DRAM 和 SSD）组成的混合内存池对应用程序性能的具体影响。</li></ul><h2 id="h2-3"><ol start="3"><li>论文发现以及论文贡献</li></ol></h2><p><b>论文发现</b></p><p>论文的核心发现是，采用 DRAM-SSD 混合内存池对应用性能的影响因工作负载的类型而异。</p><ul><li>对于<b>计算密集型工作负载</b>（如视频处理 FFmpeg 和深度学习训练 ResNet50），性能瓶颈在于计算而非内存访问延迟，因此增加 SSD 作为内存扩展几乎不影响性能，同时能显著降低成本。例如，在内存过载率（Overcommit Ratio）为 2 时，训练 ResNet50 的性能仅下降了 2.68%。</li></ul><ul><li>对于<b>I/O 密集型工作负载</b>（如数据库 TPC-C 和数据分析 TPC-H），它们对内存延迟和带宽非常敏感，性能会因混合内存池的引入而受到严重影响。</li></ul><p><b>论文贡献</b></p><p>本文的贡献主要有三点：</p><ol start="1"><li>设计了一个有效的软件模拟器：在缺少真实 CXL 硬件的情况下，利用缓存一致性的 NUMA 架构设计并实现了一个 CXL 混合内存池的软件模拟器。</li></ol><ol start="2"><li>评估了代表性工作负载：在模拟器上评估了四种代表性的云应用（视频处理、数据库、数据分析、深度学习训练），展示了与纯 DRAM 内存池相比，采用混合内存池带来的性能变化。</li></ol><ol start="3"><li>分析了性能与成本的权衡：通过改变混合内存池中 DRAM 和 SSD 的构成比例，揭示了不同应用在性能和成本之间的权衡关系。</li></ol><h2 id="h2-4"><ol start="4"><li>方法策略</li></ol></h2><ul><li><b>目标</b>：验证并量化在 CXL 内存池中引入 SSD 以降低成本的可行性及其对不同应用的性能影响。</li></ul><ul><li><b>遇到的困难</b>：最主要的困难是当前缺乏可用的真实 CXL 硬件来搭建实验平台。</li></ul><ul><li><b>设计的方法与策略</b>：<ol start="1"><li><b>利用 NUMA 架构进行模拟</b>：为了克服硬件缺失的困难，研究者选择利用现有多插槽服务器上广泛存在的非统一内存访问（NUMA）架构来模拟 CXL 内存池。选择 NUMA 的原因有二：首先，NUMA 架构是缓存一致性的，并且像 CXL 一样使用 load/store 指令进行内存访问。其次，从主 CPU 的角度看，访问远程 NUMA 节点的内存延迟与访问 CXL 附加内存的延迟相似。</li></ol><ol start="2"><li><b>构建分层内存系统</b>：<ul><li><b>本地内存（第一层）</b>：将 NUMA 节点 1 作为虚拟机的本地内存，提供最低的访问延迟。</li></ul><ul><li><b>混合内存池（第二层）</b>：将 NUMA 节点 2 的 DRAM 与一块 NVMe SSD 共同组成一个混合内存池。这一层本身又是一个子分层系统：NUMA 节点 2 的 DRAM 是其中的高速缓存层，NVMe SSD 是低速存储层。</li></ul></li></ol><ol start="3"><li><b>模拟页面迁移</b>：<ul><li><b>DRAM 与 SSD 之间</b>：利用 Linux swap 机制来模拟混合内存池内部（即 NUMA 节点 2 与 NVMe SSD 之间）的页面换入换出。当 NUMA 节点 2 的内存不足时，页面会被换出到 SSD 上。</li></ul><ul><li><b>本地与远程之间</b>：页面可以在 NUMA 节点 1 和内存池之间迁移，由 Hypervisor 支持。</li></ul></li></ol><ol start="4"><li><b>内存分配控制</b>：研究者修改了 Linux cgroups，为每个内存层级（本地 DRAM、远程 DRAM、SSD）设置独立的内存限制，从而精确控制应用程序在不同层级上可以使用的内存量。</li></ol></li></ul><h2 id="h2-5"><ol start="5"><li>实验设置与实验结果</li></ol></h2><ul><li><b>实验平台</b>：实验平台是基于商用硬件的软件模拟器，而非真实的 CXL ASIC 或 FPGA。平台配置为一台双插槽 Linux 服务器，搭载两颗 Intel Platinum 8268 CPU，384GB DDR4 DRAM，以及一块 3.5TB 的三星 PM983 SSD。通过 NUMA 架构模拟 CXL 内存池的行为。</li></ul><ul><li><b>实验设计</b>：<ul><li><b>过载率 (Overcommit Ratio)</b>：为了量化 SSD 引入的影响，论文定义了“过载率” (R)。实际使用的 DRAM 量 = 应用所需内存量 / R。R = 1 表示纯 DRAM 内存池，R &gt; 1 则表示部分内存需求由 SSD 满足。实验中 R 的取值分别为 1, 1.5, 2, 3, 4。</li></ul><ul><li><b>对比指标</b>：<ul><li><b>性能</b>：针对不同负载使用不同指标，包括 FFmpeg 的帧率 (FPS)、TPC-C 的每分钟事务数 (tpmC)、TPC-H 的查询累积运行时间和 ResNet50 的训练时间。</li></ul><ul><li><b>开销</b>：通过测量页面错误（Page Fault）数量来解释性能变化的原因。</li></ul><ul><li><b>成本</b>：计算总内存成本（Total Cost of Memory, TCM）的节省百分比。</li></ul></li></ul><ul><li><b>对比公平性与全面性</b>：<ul><li><b>公平性</b>：所有混合内存池的实验结果都与过载率为 1（即纯 DRAM 池）的基线进行比较，这是一个公平的基准。</li></ul><ul><li><b>全面性</b>：选取了视频处理、在线事务处理、数据分析和深度学习四种有代表性的云工作负载，覆盖了不同类型的应用场景。</li></ul></li></ul><ul><li><b>消融实验</b>：通过不断增加过载率（从 1.5 到 4），实验系统性地展示了增加 SSD 比例对性能和成本的影响，这可以看作是一种消融分析，证明了性能的下降和成本的节省是由 SSD 的引入直接导致的。</li></ul></li></ul><ul><li><b>实验结果</b>：<ul><li><b>FFmpeg (视频编码)</b>：性能下降幅度很小。即使过载率为 4，性能也仅下降 11.9%，因为它是计算密集型应用。</li></ul><ul><li><b>ResNet50 (深度学习)</b>：性能同样受影响较小。过载率为 4 时，性能下降 17.9%。</li></ul><ul><li><b>TPC-C (数据库)</b>：性能下降非常剧烈。过载率仅为 1.5 时，性能就骤降 55.8%，在过载率为 4 时下降了 78.5%。</li></ul><ul><li><b>TPC-H (数据分析)</b>：性能同样严重下降。过载率为 1.5 时性能下降 1.13 倍，过载率为 4 时下降 5.32 倍。</li></ul><ul><li><b>成本节省</b>：引入 SSD 可以显著节约成本。过载率为 1.5 时即可节省 32% 的总内存成本，当过载率为 4 时，可节省高达 72.5%。</li></ul></li></ul><h2 id="h2-6"><ol start="6"><li>前提假设与局限性</li></ol></h2><ul><li><b>前提假设</b>：<ol start="1"><li><b>NUMA 模拟的有效性</b>：文章假设远程 NUMA 节点的访问特性（如延迟和缓存一致性）可以作为 CXL 连接内存的合理近似。</li></ol><ol start="2"><li><b>Swap 模拟的合理性</b>：假设使用 Linux swap 机制来模拟 DRAM 和 SSD 之间的数据迁移是可行的，因为在 SSD 延迟面前，页面错误处理本身的软件开销可以被忽略。</li></ol></li></ul><ul><li><b>局限性</b>：<ol start="1"><li><b>模拟器而非真实硬件</b>：这是一个软件模拟，而非真实硬件。作者承认，使用真实的 CXL 硬件可能会获得更好的性能，因为模拟中主机端仍然存在页面错误处理的开销。</li></ol><ol start="2"><li><b>简单的页面管理策略</b>：实验使用了 Linux 默认的预取器，该预取器只能检测顺序访问模式。作者推测，TPC-C 和 TPC-H 的糟糕表现并不意味着它们完全不能用于混合内存池，如果采用更智能的页面迁移和缓存算法，性能可能会得到改善。</li></ol></li></ul></div>
    <div class="dir-tree"><ul><li><a href="../../md-docs/README" >README</a></li></ul><ul><li><a href="../../内存池化/Pond" >内存池化</a><ul><li><a href="../../内存池化/Pond" >Pond</a></li></ul><ul><li><a href="../../内存池化/Direct_CXL" >Direct_CXL</a></li></ul><ul><li><a href="../../内存池化/Against_CXL_Memory_Pooling" >Against_CXL_Memory_Pooling</a></li></ul><ul><li><a href="../../内存池化/Logical Memory Pools:  Flexible and Local Disaggregated Memory" >Logical Memory Pools:  Flexible and Local Disaggregated Memory</a></li></ul><ul><li><a href="../../内存池化/STARNUMA: Mitigating NUMA Challenges with Memory Pooling" >STARNUMA: Mitigating NUMA Challenges with Memory Pooling</a></li></ul><ul><li><a href="../../内存池化/Performance Evaluation on CXL-enabled Hybrid  Memory Pool" >Performance Evaluation on CXL-enabled Hybrid  Memory Pool</a></li></ul><ul><li><a href="../../内存池化/Memory Sharing with CXL: Hardware and Software Design Approaches" >Memory Sharing with CXL: Hardware and Software Design Approaches</a></li></ul></li></ul><ul><li><a href="../../内存分级/TPP" >内存分级</a><ul><li><a href="../../内存分级/TPP" >TPP</a></li></ul><ul><li><a href="../../内存分级/NeoMem" >NeoMem</a></li></ul></li></ul><ul><li><a href="../../带宽与延迟/Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices" >带宽与延迟</a><ul><li><a href="../../带宽与延迟/Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices" >Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices</a></li></ul><ul><li><a href="../../带宽与延迟/Systematic CXL Memory Characterization and  Performance Analysis at Scale" >Systematic CXL Memory Characterization and  Performance Analysis at Scale</a></li></ul></li></ul><ul><li><a href="../../CXL-SSD/Hello_Bytes" >CXL-SSD</a><ul><li><a href="../../CXL-SSD/Hello_Bytes" >Hello_Bytes</a></li></ul><ul><li><a href="../../CXL-SSD/Cache_in_Hand" >Cache_in_Hand</a></li></ul></li></ul><ul><li><a href="../../simulation/CXL-DMsim" >simulation</a><ul><li><a href="../../simulation/CXL-DMsim" >CXL-DMsim</a></li></ul></li></ul><ul><li><a href="../../CXL探索/Enhanced_Memory_Functions" >CXL探索</a><ul><li><a href="../../CXL探索/Enhanced_Memory_Functions" >Enhanced_Memory_Functions</a></li></ul></li></ul><ul><li><a href="../../内存拓展/Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller" >内存拓展</a><ul><li><a href="../../内存拓展/Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller" >Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller</a></li></ul><ul><li><a href="../../内存拓展/Accelerating_Performance_of_GPU-based_Workloads_Using_CXL" >Accelerating_Performance_of_GPU-based_Workloads_Using_CXL</a></li></ul></li></ul><ul><li><a href="../../Prefetch/Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching" >Prefetch</a><ul><li><a href="../../Prefetch/Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching" >Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching</a></li></ul></li></ul></div>
    <div class="zood"><a class="" href="https://github.com/luzhixing12345/zood" target="_blank">zood</a></div>
    <script type="text/javascript" src="../../../js/next_front.js"></script><script>addLink("../../内存池化/STARNUMA: Mitigating NUMA Challenges with Memory Pooling","../../内存池化/Memory Sharing with CXL: Hardware and Software Design Approaches","ab");</script><script type="text/javascript" src="../../../js/change_mode.js"></script><script>addChangeModeButton("../../../img/sun.png","../../../img/moon.png");</script><script type="text/javascript" src="../../../js/copy_code.js"></script><script>addCodeCopy("../../../img/clipboard.svg","../../../img/clipboard-check.svg");</script><script type="text/javascript" src="../../../js/navigator.js"></script><script type="text/javascript" src="../../../js/picture_preview.js"></script><script type="text/javascript" src="../../../js/global_js_configuration.js"></script>
</body>

</html>