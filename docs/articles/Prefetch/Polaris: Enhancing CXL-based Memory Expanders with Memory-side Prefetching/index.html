<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
        Document
    </title>
    <link rel='stylesheet' href=../../../css/index.css />
    
    <link rel="icon" href="https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png">
</head>

<body class="light">
    <a href="https://github.com/IcarusSong/cxl-papers.git" target="_blank" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <div class="header-navigator"><ul><li><a href="#h1-0">Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching</a><ul><li><a href="#h2-1">作者以及出版物</a><ul><li><a href="#h3-2">作者</a></li></ul><ul><li><a href="#h3-3">出版物</a></li></ul></li></ul><ul><li><a href="#h2-4">1. 文章背景</a></li></ul><ul><li><a href="#h2-5">2. 相关工作以及局限性</a></li></ul><ul><li><a href="#h2-6">3. 论文发现以及论文贡献</a></li></ul><ul><li><a href="#h2-7">4. 方法策略（如何利用这个发现，遇到了什么困难？设计了什么方法-策略）</a></li></ul><ul><li><a href="#h2-8">5. 实验设置与实验结果</a></li></ul><ul><li><a href="#h2-9">6. 前提假设与局限性</a></li></ul><ul><li><a href="#h2-10">7. 改进方向</a></li></ul></li></ul></div><div class='markdown-body'><h1 id="h1-0">Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching</h1><h2 id="h2-1">作者以及出版物</h2><h3 id="h3-2">作者</h3><ol start="1"><li><p><b>Zhe Zhou (周哲)</b>：北京大学集成电路学院，北京大学计算机学院。</p></li></ol><ol start="2"><li><p><b>Shuotao Xu (徐硕涛)</b>：微软亚洲研究院。</p></li></ol><ol start="3"><li><p><b>Yiqi Chen (陈一琦)</b>：北京大学集成电路学院。</p></li></ol><ol start="4"><li><p><b>Tao Zhang (张涛)</b>：微软亚洲研究院。</p></li></ol><ol start="5"><li><p><b>Ran Shu (舒然)</b>：微软亚洲研究院。</p></li></ol><ol start="6"><li><p><b>Lei Qu (屈磊)</b>：微软亚洲研究院。</p></li></ol><ol start="7"><li><p><b>Peng Cheng (程鹏)</b>：微软亚洲研究院。</p></li></ol><ol start="8"><li><p><b>Yongqiang Xiong (熊永强)</b>：微软亚洲研究院。</p></li></ol><ol start="9"><li><p><b>Guangyu Sun (孙广宇)</b>：北京大学集成电路学院，北京大学计算机学院，北京集成电路高精尖创新中心。他是本文的通讯作者（Corresponding author），通常负责论文的主要研究工作和投稿事宜。</p></li></ol><h3 id="h3-3">出版物</h3><p>APPT&#x27;23</p><h2 id="h2-4"><ol start="1"><li>文章背景</li></ol></h2><p>随着数据中心对内存容量和带宽的需求不断增长，传统的服务器内存扩展方式（如增加更多DDR通道）遇到了瓶瓶颈。<b>Compute Express Link (CXL)</b> 协议作为一种新兴的开放标准，提供了一种高效的解决方案。它允许CPU通过高速互联总线，以缓存一致性（cache-coherent）的方式访问连接在CXL总线上的内存扩展设备（CXL内存）。 <a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880ee5558cb8da5c8d1acfd.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880ee5558cb8da5c8d1acfd.png" alt=""></a> <b>核心问题</b>：尽管CXL内存比过去的PCIe或RDMA扩展方案延迟低得多，但由于控制和传输开销，其访问延迟仍然是本地DDR内存的<b>约2倍</b>。这种延迟差距会严重影响对延迟敏感型工作负载的性能，甚至导致高达50%的性能下降。如何弥合CXL内存与本地内存之间的性能差距，是充分发挥CXL优势的关键挑战。</p><h2 id="h2-5"><ol start="2"><li>相关工作以及局限性</li></ol></h2><p>为了解决CXL内存的高延迟问题，研究者们探索了多种方法，但都存在局限性：</p><ol start="1"><li><p><b>系统级优化（热/冷数据分层）</b>:</p><ul><li><p><b>方法</b>: 通过操作系统（OS）或应用程序，将访问频繁的“热”数据放置在低延迟的本地内存中，将不常用的“冷”数据放置在高延迟的CXL内存中。</p></li></ul><ul><li><p><b>局限性</b>:</p></li></ul><ul><li><p><b>需要复杂修改</b>: 需要修改操作系统内核或应用程序，部署成本高。</p></li></ul><ul><li><p><b>粗粒度管理</b>: 通常以内存页（Page）或虚拟机（VM）为单位进行数据迁移，粒度较粗。这会引发<b>读/写放大</b>问题，并且无法充分利用CXL支持细粒度（缓存行级别）访问的优势。</p></li></ul></li></ol><ol start="2"><li><p><b>CPU侧缓存预取（CPU-side Prefetching）</b>:</p><ul><li><p><b>方法</b>: 利用CPU自身的硬件预取器来预测并提前加载CXL内存中的数据到CPU缓存中，从而隐藏访问延迟。</p></li></ul><ul><li><p><b>局限性 (论文的核心论点之一)</b>:</p></li></ul><ul><li><p><b>覆盖率与准确率的矛盾</b>: 为了隐藏CXL的长延迟，CPU预取器需要变得非常“激进”以提高预取覆盖率。然而，激进的预取通常会导致预取准确率下降。</p></li></ul><ul><li><p><b>缓存污染 (Cache Pollution)</b>: 不准确的预取会将无用的数据加载到CPU缓存中，挤出有用的数据，导致缓存效率下降。</p></li></ul><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880eedf58cb8da5c8d1b24a.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880eedf58cb8da5c8d1b24a.png" alt=""></a></p><ul><li><p><b>带宽浪费 (Bandwidth Waste)</b>: 错误的预取会消耗宝贵的CPU到CXL设备的内存带宽。</p></li></ul><ul><li><p><b>修改成本高</b>: 专门为CXL优化或设计新的CPU预取器，需要对CPU进行昂贵的硬件修改，实施难度大。</p></li></ul></li></ol><p>论文通过对最先进的CPU预取器（如Pythia）的评估，证明了即使是强大的CPU预取器也无法有效解决CXL的延迟问题，仍然有大量任务性能受损严重。 <a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880eea258cb8da5c8d1b007.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880eea258cb8da5c8d1b007.png" alt=""></a> <a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880eec858cb8da5c8d1b173.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880eec858cb8da5c8d1b173.png" alt=""></a></p><h2 id="h2-6"><ol start="3"><li>论文发现以及论文贡献</li></ol></h2><ul><li><p><b>论文发现</b>: 论文通过实验发现，单纯依赖CPU侧的预取机制存在一个难以调和的根本性矛盾：<b>在CXL场景下，为追求高预取覆盖率而采取的激进策略，会不可避免地导致严重的缓存污染和带宽浪费，从而限制了性能提升的上限</b>。因此，需要跳出“在CPU侧解决问题”的思维定式。</p></li></ul><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880ee7458cb8da5c8d1ae32.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880ee7458cb8da5c8d1ae32.png" alt=""></a></p><ul><li><p><b>论文贡献</b>:</p><ol start="1"><li><p><b>提出POLARIS框架</b>: 首次提出了一种在<b>CXL内存扩展设备侧（Memory-side）</b>集成硬件预取器的创新方案，名为POLARIS。这是一种近内存计算（Near-memory processing）的实践。</p></li></ol><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880ef0f58cb8da5c8d1b3fd.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880ef0f58cb8da5c8d1b3fd.png" alt=""></a></p><ol start="2"><li><p><b>设计POLARIS-Base</b>: 一个<b>非侵入式</b>的基础版本。它无需修改CPU或软件，可作为现有服务器的“即插即用”升级方案。它在CXL控制器中集成预取器和专用的SRAM缓存（PFB），为预取命中的请求建立“快捷方式”，显著降低延迟。</p></li></ol><ol start="3"><li><p><b>设计POLARIS-Active</b>: 一个更高性能的<b>主动</b>版本。它提出只需对CPU进行微小的修改（如扩展Intel的DDIO功能），就能将高置信度的预取数据<b>主动推送（push）</b>到CPU的末级缓存（LLC）中，从而最大程度地隐藏CXL访问延迟。</p></li></ol><ol start="4"><li><p><b>提出集成的动态预取器选择机制</b>: POLARIS不使用单一的预取器，而是<b>集成了四种不同的预取器</b>，并设计了一套基于分数的动态选择机制，可以在运行时为当前的工作负载选择表现最好的预取器，从而兼顾了覆盖率和准确率。</p></li></ol><ol start="5"><li><p><b>全面的模拟和评估</b>: 通过详尽的模拟实验，证明了POLARIS相比多种CPU侧预取器方案，能更有效地弥合CXL内存的性能鸿沟。</p></li></ol></li></ul><h2 id="h2-7"><ol start="4"><li>方法策略（如何利用这个发现，遇到了什么困难？设计了什么方法-策略）</li></ol></h2><p><b>核心策略</b>：将预取功能从CPU侧转移到CXL内存设备侧。</p><p><b>POLARIS-Base 的设计</b>：</p><ul><li><p><b>如何工作</b>:</p><ol start="1"><li><p>在CXL内存控制器芯片上集成一个硬件预取器和一个专用的SRAM缓存，称为<b>预取缓冲区 (Prefetch Buffer, PFB)</b>。</p></li></ol><ol start="2"><li><p>当CPU的读请求到达CXL设备时，该请求地址会被送入PFB进行查询，同时也被送入预取器进行分析。</p></li></ol><ol start="3"><li><p><b>如果请求在PFB中命中</b>：数据直接从高速的PFB（SRAM）返回给CPU，绕过了访问慢速DRAM的路径，形成了一条“快捷方式”，大大缩短了延迟。</p></li></ol><ol start="4"><li><p><b>如果请求在PFB中未命中</b>: 请求正常转发至设备上的DRAM，并将返回的数据发送给CPU。</p></li></ol><ol start="5"><li><p>与此同时，设备侧的预取器会根据历史访问模式，预测CPU接下来可能需要的数据，并提前从DRAM中将这些数据加载到PFB中，为下一次“命中”做准备。</p></li></ol></li></ul><ul><li><p><b>遇到的困难与解决方案</b>:</p><ul><li><p><b>困难</b>: 如何避免影响正常的内存访问路径？</p></li></ul><ul><li><p><b>方案</b>: 采用并行查询设计，PFB不处在访问DRAM的关键路径上。请求同时查询PFB和发往DRAM队列，如果PFB命中，则从DRAM队列中撤销该请求，节省DRAM带宽。</p></li></ul></li></ul><p><b>Ensembled Prefetcher (集成预取器) 的设计</b>：</p><ul><li><p><b>遇到的困难与解决方案</b>:</p><ul><li><p><b>困难</b>: 经过CPU多级缓存的过滤，到达CXL内存的访问模式非常不规律，单一的预取算法难以适应所有工作负载。</p></li></ul><ul><li><p><b>方案</b>:</p></li></ul><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880ef3958cb8da5c8d1b5ac.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880ef3958cb8da5c8d1b5ac.png" alt=""></a></p><ol start="1"><li><p><b>集成 (Ensemble)</b>: 集成了四种经典的、仅依赖物理地址的预取器（BOP, Domino, SPP, VLDP）。</p></li></ol><ol start="2"><li><p><b>动态选择 (Score-based Selector)</b>: 设计了一套巧妙的“虚拟预取”机制。所有预取器只“生成”预测地址，但不实际执行预取。这些预测地址被记录在各自的布隆过滤器（Bloom Filter）中。当一个真实的CPU请求到来时，系统会检查它是否在某个预取器的布隆过滤器中（即“虚拟命中”）。虚拟命中次数最多的预取器得分最高，POLARIS会采用该预取器进行<b>实际的</b>预取操作。这个机制能动态选出当前最优的预取器。</p></li></ol></li></ul><p><b>POLARIS-Active 的设计</b>：</p><ul><li><p><b>遇到的困难与解决方案</b>:</p><ul><li><p><b>困难1：数据一致性</b>。直接将数据推送到CPU的LLC，可能会覆盖掉CPU中更新的、尚未写回的“脏”数据。标准的DDIO（Direct Data I/O）机制存在此问题。</p></li></ul><ul><li><p><b>方案1</b>: 提出对DDIO协议进行微小扩展，增加一个<b><code>Write-Ignore</code></b>（写忽略）操作。当POLARIS推送的预取数据在LLC中已存在时，CPU直接忽略这次写入，从而保证了LLC中数据的新鲜度。</p></li></ul><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880ef6258cb8da5c8d1b72b.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880ef6258cb8da5c8d1b72b.png" alt=""></a></p><ul><li><p><b>困难2：带宽和缓存资源的浪费</b>。主动推送会消耗CXL链路带宽和LLC缓存空间，如果推送的数据不准，得不偿失。</p></li></ul><ul><li><p><b>方案2</b>: <b>只推送高置信度的预取</b>。通过集成预取器的得分机制计算出当前预取器的<b>准确率（Accuracy）</b>。只有当准确率超过一个预设阈值<code>T</code>时，才触发主动推送；否则，仍然只将数据预取到设备侧的PFB中。</p></li></ul></li></ul><h2 id="h2-8"><ol start="5"><li>实验设置与实验结果</li></ol></h2><ul><li><p><b>实验平台</b>: 论文使用的是一个<b>周期精确的模拟器（cycle-accurate ChampSim simulator）</b>。他们修改了模拟器以支持CXL通道、延迟注入、PFB以及内存侧预取器等行为。<b>这不是真实的CXL ASIC、NUMA模拟或FPGA平台</b>，这是计算机体系结构研究中常见的、用于早期设计验证的学术方法。</p></li></ul><ul><li><p><b>实验效果与对比指标</b>:</p><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880ef9c58cb8da5c8d1b961.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880ef9c58cb8da5c8d1b961.png" alt=""></a></p><ul><li><p><b>核心指标</b>: <code>Slowdown</code>（公式3）。该指标计算了“使用CXL内存时的IPC”相对于“使用本地DDR内存时的IPC”的性能下降百分比。<code>Slowdown</code>越接近0，说明CXL延迟被隐藏得越好。</p></li></ul><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880efc258cb8da5c8d1ba21.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880efc258cb8da5c8d1ba21.png" alt=""></a></p><ul><li><p><b>效果</b>:</p></li></ul><ul><li><p>在单核场景下，POLARIS能将原本高达-25%的平均性能下降，缓解到-1%至-10%的水平。</p></li></ul><ul><li><p><b>POLARIS平均能让43%的工作负载“有效容忍”（性能差距&lt;5%）CXL的长延迟</b>，在某些配置下这一比例高达85%。</p></li></ul><ul><li><p>在多核场景下，POLARIS-Active甚至能实现比本地内存更高的性能（IPC提升8%），因为它补偿了没有CPU侧预取器的情况。</p></li></ul></li></ul><ul><li><p><b>对比公平性与全面性</b>:</p><ul><li><p><b>公平性</b>: 对比非常公平。它将POLARIS与多种基准进行了比较：1）无预取器；2）商业CPU中常用的Streamer预取器；3）开源CPU中使用的BOP预取器；4）最先进的学术研究成果Pythia预取器。在对比时，CPU侧的配置保持一致。</p></li></ul><ul><li><p><b>全面性</b>: 实验设计非常全面。</p></li></ul><ul><li><p><b>解决问题效果好</b>: 通过对比有无POLARIS的<code>Slowdown</code>（图9），证明了其有效性。</p></li></ul><ul><li><p><b>比相关工作好</b>: 通过与多种CPU侧预取器对比，证明了内存侧预取的优越性。</p></li></ul><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880f05658cb8da5c8d1be61.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880f05658cb8da5c8d1be61.png" alt=""></a></p><ul><li><p><b>效果合理性分析</b>: 通过分析预取覆盖率（图12），展示了POLARIS额外覆盖了大量CPU预取器未命中的情况，解释了性能提升的来源。</p></li></ul><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880eff758cb8da5c8d1bae6.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880eff758cb8da5c8d1bae6.png" alt=""></a> <a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880f01958cb8da5c8d1bc6a.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880f01958cb8da5c8d1bc6a.png" alt=""></a> <a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880f04358cb8da5c8d1bdd4.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880f04358cb8da5c8d1bdd4.png" alt=""></a></p><ul><li><p><b>消融实验</b>: 通过对比集成预取器与单个预取器的性能（图13），证明了集成与动态选择机制的优越性。还通过改变DRAM带宽（图14）和PFB大小（图15）进行了敏感性分析，验证了设计的合理性和鲁棒性。</p></li></ul></li></ul><h2 id="h2-9"><ol start="6"><li>前提假设与局限性</li></ol></h2><ul><li><p><b>前提假设</b>:</p><ol start="1"><li><p><b>微小的CPU修改可行性</b>: POLARIS-Active的实现依赖于CPU厂商愿意对其DDIO逻辑进行微小修改（增加<code>Write-Ignore</code>功能）。这是一个重要但并非不切实际的假设。</p></li></ol><ol start="2"><li><p><b>设备侧资源预算</b>: 假设CXL内存扩展卡的制造商有足够的芯片面积（约27.1 mm²）和功耗预算（约1.77 W）来集成预取器逻辑和PFB缓存。</p></li></ol><ol start="3"><li><p><b>设备侧带宽有富余</b>: 设计利用了设备侧DRAM带宽高于CXL链路带宽这一特点。这在当前标准下成立，但未来可能改变。</p></li></ol></li></ul><ul><li><p><b>局限性</b>:</p><ol start="1"><li><b>CPU侧与设备侧协同问题</b>：论文中，CPU侧的预取请求也会被设备侧当成普通的内存请求，没有和设备测的预取器进行很好的协同。</li></ol><p><a data-lightbox="example-1" href="https://pic1.imgdb.cn/item/6880f09558cb8da5c8d1bff7.png"><img loading="lazy" src="https://pic1.imgdb.cn/item/6880f09558cb8da5c8d1bff7.png" alt=""></a></p><ol start="2"><li><p><b>多核扩展性问题</b>: 论文指出，在8核等高负载场景下，POLARIS-Active与某些CPU预取器（如BOP）结合使用时性能会下降，原因是DDIO资源和CXL带宽竞争激烈。作者承认，针对多核场景优化参数是未来工作。</p></li></ol><ol start="3"><li><p><b>对写操作的关注较少</b>: 论文主要关注由读请求引发的延迟问题，对写密集型工作负载的影响分析不够深入。</p></li></ol></li></ul><h2 id="h2-10"><ol start="7"><li>改进方向</li></ol></h2><ol start="1"><li>增加Host侧（CPU/OS）与设备侧的协同，比如OS读取设备测的数据，进行更加智能的预取。</li></ol></div>
    <div class="dir-tree"><ul><li><a href="../../md-docs/README" >README</a></li></ul><ul><li><a href="../../内存池化/Pond" >内存池化</a><ul><li><a href="../../内存池化/Pond" >Pond</a></li></ul><ul><li><a href="../../内存池化/Direct_CXL" >Direct_CXL</a></li></ul><ul><li><a href="../../内存池化/Against_CXL_Memory_Pooling" >Against_CXL_Memory_Pooling</a></li></ul><ul><li><a href="../../内存池化/Logical Memory Pools:  Flexible and Local Disaggregated Memory" >Logical Memory Pools:  Flexible and Local Disaggregated Memory</a></li></ul><ul><li><a href="../../内存池化/STARNUMA: Mitigating NUMA Challenges with Memory Pooling" >STARNUMA: Mitigating NUMA Challenges with Memory Pooling</a></li></ul><ul><li><a href="../../内存池化/Performance Evaluation on CXL-enabled Hybrid  Memory Pool" >Performance Evaluation on CXL-enabled Hybrid  Memory Pool</a></li></ul><ul><li><a href="../../内存池化/Memory Sharing with CXL: Hardware and Software Design Approaches" >Memory Sharing with CXL: Hardware and Software Design Approaches</a></li></ul></li></ul><ul><li><a href="../../内存分级/TPP" >内存分级</a><ul><li><a href="../../内存分级/TPP" >TPP</a></li></ul><ul><li><a href="../../内存分级/NeoMem" >NeoMem</a></li></ul></li></ul><ul><li><a href="../../带宽与延迟/Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices" >带宽与延迟</a><ul><li><a href="../../带宽与延迟/Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices" >Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices</a></li></ul><ul><li><a href="../../带宽与延迟/Systematic CXL Memory Characterization and  Performance Analysis at Scale" >Systematic CXL Memory Characterization and  Performance Analysis at Scale</a></li></ul></li></ul><ul><li><a href="../../CXL-SSD/Hello_Bytes" >CXL-SSD</a><ul><li><a href="../../CXL-SSD/Hello_Bytes" >Hello_Bytes</a></li></ul><ul><li><a href="../../CXL-SSD/Cache_in_Hand" >Cache_in_Hand</a></li></ul></li></ul><ul><li><a href="../../simulation/CXL-DMsim" >simulation</a><ul><li><a href="../../simulation/CXL-DMsim" >CXL-DMsim</a></li></ul></li></ul><ul><li><a href="../../CXL探索/Enhanced_Memory_Functions" >CXL探索</a><ul><li><a href="../../CXL探索/Enhanced_Memory_Functions" >Enhanced_Memory_Functions</a></li></ul></li></ul><ul><li><a href="../../内存拓展/Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller" >内存拓展</a><ul><li><a href="../../内存拓展/Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller" >Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller</a></li></ul><ul><li><a href="../../内存拓展/Accelerating_Performance_of_GPU-based_Workloads_Using_CXL" >Accelerating_Performance_of_GPU-based_Workloads_Using_CXL</a></li></ul></li></ul><ul><li><a href="../../Prefetch/Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching" >Prefetch</a><ul><li><a href="../../Prefetch/Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching" >Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching</a></li></ul></li></ul></div>
    <div class="zood"><a class="" href="https://github.com/luzhixing12345/zood" target="_blank">zood</a></div>
    <script type="text/javascript" src="../../../js/next_front.js"></script><script>addLink("../../内存拓展/Accelerating_Performance_of_GPU-based_Workloads_Using_CXL",".","ab");</script><script type="text/javascript" src="../../../js/change_mode.js"></script><script>addChangeModeButton("../../../img/sun.png","../../../img/moon.png");</script><script type="text/javascript" src="../../../js/copy_code.js"></script><script>addCodeCopy("../../../img/clipboard.svg","../../../img/clipboard-check.svg");</script><script type="text/javascript" src="../../../js/navigator.js"></script><script type="text/javascript" src="../../../js/picture_preview.js"></script><script type="text/javascript" src="../../../js/global_js_configuration.js"></script>
</body>

</html>