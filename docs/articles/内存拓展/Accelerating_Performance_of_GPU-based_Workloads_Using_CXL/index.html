<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
        Document
    </title>
    <link rel='stylesheet' href=../../../css/index.css />
    
    <link rel="icon" href="https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png">
</head>

<body class="light">
    <a href="https://github.com/IcarusSong/cxl-papers.git" target="_blank" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <div class="header-navigator"><ul><li><a href="#h1-0">Accelerating_Performance_of_GPU-based_Workloads_Using_CXL</a><ul><li><a href="#h2-1">作者和出版物</a><ul><li><a href="#h3-2">作者</a></li></ul><ul><li><a href="#h3-3">出版物</a></li></ul></li></ul><ul><li><a href="#h2-4">文章背景</a><ul><li><a href="#h3-5">相关工作以及局限性</a></li></ul><ul><li><a href="#h3-6">论文发现以及论文贡献</a></li></ul><ul><li><a href="#h3-7">方法策略</a></li></ul><ul><li><a href="#h3-8">实验设置与实验结果</a></li></ul><ul><li><a href="#h3-9">前提假设与局限性</a></li></ul></li></ul></li></ul></div><div class='markdown-body'><h1 id="h1-0">Accelerating_Performance_of_GPU-based_Workloads_Using_CXL</h1><h2 id="h2-1">作者和出版物</h2><h3 id="h3-2">作者</h3><ul><li>Moiz Arif，Rochester Institute of Technology，Rochester, NY, USA，ma3890@cs.rit.edu</li></ul><ul><li>Avinash Maurya，Rochester Institute of Technology，Rochester, NY, USA，am6429@cs.rit.edu</li></ul><ul><li>M. Mustafa Rafique，Rochester Institute of Technology，Rochester, NY, USA，mrafique@cs.rit.edu</li></ul><h3 id="h3-3">出版物</h3><p>FlexScience’23, June 20, 2023, Orlando, FL, USA</p><h2 id="h2-4">文章背景</h2><p>在高性能计算（HPC）领域，科学模拟和深度学习（DL）等工作负载通常在多GPU系统上运行，它们是内存和数据密集型的。这些工作负载依赖于主内存来补充GPU上容量有限的板载高带宽内存（HBM）。为了在较慢的设备到主机PCIe互连上实现更快的数据传输，这些工作负载通常会在主机系统上“钉住”（pin）内存。然而，在多GPU节点上，这种内存钉住（pinning）操作会限制了其他GPU可用主内存的容量，可能导致显著的数据传输开销，甚至因无法钉住所需要的内存量而导致作业失败。</p><p>Compute Express Link (CXL) 是一种新兴技术，它能以低延迟和高吞吐量的方式透明地扩展系统内存容量，并保持缓存一致性。虽然这为多GPU节点上的工作负载分配和钉住更多内存提供了可能，但使用传统的内存分配方案可能会因CXL内存上的争用而对数据吞吐量产生负面影响。</p><h3 id="h3-5">相关工作以及局限性</h3><p>文章将相关工作分为两类：</p><ul><li><b>分层内存的内存管理方法</b>：一些工作提出了针对CXL内存的透明页面放置机制，根据页面的“冷热”程度在不同内存层级间移动页面。例如，Radient提出了高效的页面放置策略，动态管理主存和NVMe之间的页面。HotBox则是一个旨在最大化本地内存命中率的内存管理子系统。<ul><li><b>局限性</b>：这些分层内存管理方法都没有考虑到在启用CXL的多GPU设置中分配“钉住内存”（pinned memory）的特定情况。</li></ul></li></ul><ul><li><b>使用CXL进行内存分解</b>：近期的研究利用CXL来实现分解式内存系统，允许以低开销访问TB级的内存。一些研究利用基于CXL的内存作为扩展设备来提升工作负载性能。例如，CMS通过利用CXL互连来扩展内存容量，并使用近数据处理方法来最大化内部带宽。<ul><li><b>局限性</b>：这些研究尚未探讨通过PCIe通道连接CXL内存时可能出现的带宽瓶颈问题。</li></ul></li></ul><h3 id="h3-6">论文发现以及论文贡献</h3><ul><li><b>论文发现</b>：论文的核心发现是，尽管CXL内存为系统扩展了容量，但允许操作系统或GPU驱动程序独立于其他工作负载进行内存分配，会导致次优的内存布局。这种低效的映射会增加应用程序的执行时间，降低内存吞吐量和带宽利用率。当多个作业被调度到同一插槽（socket）的GPU上时，默认的内存分配策略（先用完DRAM再用CXL）会导致后启动的作业被迫使用带宽有限的CXL内存，从而产生严重的带宽争用问题。</li></ul><ul><li><b>论文贡献</b>：<ol start="1"><li>提出了一个在Nvidia DGX-A100系统中启用CXL内存扩展的参考架构。</li></ol><ol start="2"><li>指出了在CXL系统上运行多个作业时，默认内存分配策略带来的性能瓶颈。</li></ol><ol start="3"><li>提出了一种感知调度（schedule-aware）的内存分配方法，该方法结合了多GPU系统每个插槽的内存需求，并提供高效的内存放置图以减轻内存争用。</li></ol><ol start="4"><li>通过多样化的作业配置文件和系统配置对所提方法进行了评估，模拟结果显示，与现有方法相比，其数据传输时间最多可降低65%。</li></ol></li></ul><h3 id="h3-7">方法策略</h3><ul><li><b>如何利用这个发现</b>：研究团队利用其关于“CXL内存争用”的发现，设计了一种能够智能地跨越主内存（DRAM）和CXL内存层级进行分配的策略，目标是最大化数据传输速率并减少总执行时间。</li></ul><ul><li><b>遇到了什么困难</b>：主要困难是CXL内存上的带宽争用。当多个GPU同时从连接在同一个PCIe链路上的CXL设备读写数据时，CXL内存的带宽会被所有GPU平分，从而在PCIe互连上产生争用，这会严重影响那些被分配到CXL内存的作业的读写吞吐量。</li></ul><ul><li><b>设计了什么方法-策略</b>：论文提出了一种名为“感知调度的数据分配方法” (Schedule Aware Data Allocation Approach)，其过程记录在算法1中。<ol start="1"><li><b>输入</b>：算法的输入包括节点上的插槽数、待执行的作业列表（含作业ID、总内存需求、所需GPU数）、可用的GPU列表、每个插槽可用的DRAM和CXL内存量，以及DRAM、PCIe和CXL的带宽。</li></ol><ol start="2"><li><b>作业选择</b>：首先，从作业队列中选择一批可以在当前可用GPU资源上执行的作业。</li></ol><ol start="3"><li><b>计算内存溢出 (Spill)</b>：对于每个被调度的作业，算法会计算其在公平共享DRAM的情况下，超出DRAM容量的内存需求部分，这部分被称为“spill”。</li></ol><ol start="4"><li><b>计算CXL分配量</b>：基于计算出的“spill”量、CXL可用内存以及DRAM、PCIe和CXL的各自带宽，算法会计算出可以被高效分配到CXL设备上的内存量，同时确保同一插槽上的其他作业不会面临DRAM饥饿问题。</li></ol><ol start="5"><li><b>生成分配计划</b>：最后，算法为每个作业确定在DRAM和CXL上的具体内存分配量，并更新可用的内存资源，最终输出一个高效的多层内存分配计划。</li></ol></li></ul><h3 id="h3-8">实验设置与实验结果</h3><ul><li><b>实验平台</b>：实验并非在真实的CXL硬件上进行，而是通过一个用Python编写的模拟模型来完成的。该模拟器在一个配备两颗Intel Xeon Gold 6240R处理器和192 GB主内存的服务器上运行。模拟的系统架构扩展自Nvidia DGX-A100，每个插槽（socket）有4个GPU，并通过PCIe Gen 4.0连接到主机。</li></ul><ul><li><b>效果如何</b>：该方法效果显著。与默认的“朴素”（Naive）分配方法相比，新方法将数据传输开销降低了15.4%至61.2%。在变化的PCIe带宽测试中，新方法比“朴素”和“统一”（Uniform）分配方法平均好65.35%和21.3%。总体而言，模拟结果表明，该方法相比现有分配方式，数据传输开销最多可降低65%。</li></ul><ul><li><b>对比的指标</b>：主要的性能评估指标是数据传输时间 (Data Transfer Time)。</li></ul><ul><li><b>对比是否公平？是否全面？</b><ul><li><b>公平性</b>：对比是公平的。论文将自己的方法与两种基准方法进行了比较：</li></ul><ol start="1"><li><b>Naive (朴素)</b>：默认的内存分配方式，即先用尽主内存，再使用CXL内存。</li></ol><ol start="2"><li><b>Uniform (统一)</b>：调度器将可用的主内存在所有GPU之间均匀分配。</li></ol><p>这两种方法代表了当前系统可能采用的分配策略，为评估新方法的优越性提供了合理的基线。</p><ul><li><b>全面性</b>：实验设计较为全面。研究人员通过改变三个关键变量来评估不同方法的性能：</li></ul><ol start="1"><li>每个插槽可用的主内存容量。</li></ol><ol start="2"><li>可用的PCIe带宽（模拟从PCIe 3.0开始的不同PCIe代际）。</li></ol><ol start="3"><li>不同程度的CXL惩罚（CXL penalty），即CXL协议只能实现PCIe实际带宽的60%-90%。</li></ol></li></ul><ul><li><b>实验设计分析</b>：<ul><li><b>解决问题效果</b>：图2 (a, b, c)清晰地显示，在所有测试场景下，“Our Approach”的数据传输时间均显著低于“Naive”和“Uniform”方法，证明了其有效性。</li></ul><ul><li><b>比相关工作好</b>：实验结果一致表明，该方法优于作为对比的“Naive”和“Uniform”基准方法。</li></ul><ul><li><b>效果合理性</b>：其效果之所以更好是合理的，因为它通过智能感知作业调度和系统资源状况，主动避免了“Naive”方法中的资源抢占和“Uniform”方法中可能出现的低效分配，从而最小化了由带宽争用导致的数据传输瓶颈。</li></ul><ul><li><b>消融实验</b>：“Naive”和“Uniform”方法的对比可以看作是一种消融分析。它证明了仅仅增加CXL内存（如“Naive”方法）或采用简单的公平分配策略（如“Uniform”方法）是不够的，必须采用论文中提出的更智能的、感知调度的分配策略才能取得最佳效果。</li></ul></li></ul><h3 id="h3-9">前提假设与局限性</h3><ul><li><b>前提假设</b>：论文的设计和评估基于以下几个明确的假设：<ol start="1"><li>作业队列中总是有足够的作业来占用系统上所有可用的GPU。</li></ol><ol start="2"><li>每个作业所需的内存都在应用程序初始化时被钉住（pinned），以实现更高的DMA传输速率，并且在作业完成前不能调整大小。</li></ol><ol start="3"><li>所有作业都指定了唯一的内存需求，并且在整个执行过程中内存占用保持不变。</li></ol><ol start="4"><li>所有作业都是内存密集型的，会持续地对主内存和CXL内存层中的数据进行读写。</li></ol><ol start="5"><li>CXL设备具有足够大的容量来满足所有活跃和已调度作业的内存需求。</li></ol></li></ul><ul><li><b>局限性</b>：<ol start="1"><li><b>模拟而非实物</b>：评估是基于初步的模拟，而不是在真实的CXL硬件上进行的，这可能无法完全捕捉到真实世界的所有复杂性。</li></ol><ol start="2"><li><b>带宽瓶颈</b>：论文承认，连接CXL设备的有限PCIe带宽本身就是一个瓶颈，尤其是在默认调度下。</li></ol><ol start="3"><li><b>静态内存分配</b>：当前的方法不支持动态内存大小调整，这是未来计划改进的方向。</li></ol></li></ul></div>
    <div class="dir-tree"><ul><li><a href="../../md-docs/README" >README</a></li></ul><ul><li><a href="../../内存池化/Pond" >内存池化</a><ul><li><a href="../../内存池化/Pond" >Pond</a></li></ul><ul><li><a href="../../内存池化/Direct_CXL" >Direct_CXL</a></li></ul><ul><li><a href="../../内存池化/Against_CXL_Memory_Pooling" >Against_CXL_Memory_Pooling</a></li></ul><ul><li><a href="../../内存池化/Logical Memory Pools:  Flexible and Local Disaggregated Memory" >Logical Memory Pools:  Flexible and Local Disaggregated Memory</a></li></ul><ul><li><a href="../../内存池化/STARNUMA: Mitigating NUMA Challenges with Memory Pooling" >STARNUMA: Mitigating NUMA Challenges with Memory Pooling</a></li></ul><ul><li><a href="../../内存池化/Performance Evaluation on CXL-enabled Hybrid  Memory Pool" >Performance Evaluation on CXL-enabled Hybrid  Memory Pool</a></li></ul><ul><li><a href="../../内存池化/Memory Sharing with CXL: Hardware and Software Design Approaches" >Memory Sharing with CXL: Hardware and Software Design Approaches</a></li></ul></li></ul><ul><li><a href="../../内存分级/TPP" >内存分级</a><ul><li><a href="../../内存分级/TPP" >TPP</a></li></ul><ul><li><a href="../../内存分级/NeoMem" >NeoMem</a></li></ul></li></ul><ul><li><a href="../../带宽与延迟/Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices" >带宽与延迟</a><ul><li><a href="../../带宽与延迟/Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices" >Demystifying_CXL_Memory_with_Genuine_CXL-Ready_Systems_and_Devices</a></li></ul><ul><li><a href="../../带宽与延迟/Systematic CXL Memory Characterization and  Performance Analysis at Scale" >Systematic CXL Memory Characterization and  Performance Analysis at Scale</a></li></ul></li></ul><ul><li><a href="../../CXL-SSD/Hello_Bytes" >CXL-SSD</a><ul><li><a href="../../CXL-SSD/Hello_Bytes" >Hello_Bytes</a></li></ul><ul><li><a href="../../CXL-SSD/Cache_in_Hand" >Cache_in_Hand</a></li></ul></li></ul><ul><li><a href="../../simulation/CXL-DMsim" >simulation</a><ul><li><a href="../../simulation/CXL-DMsim" >CXL-DMsim</a></li></ul></li></ul><ul><li><a href="../../CXL探索/Enhanced_Memory_Functions" >CXL探索</a><ul><li><a href="../../CXL探索/Enhanced_Memory_Functions" >Enhanced_Memory_Functions</a></li></ul></li></ul><ul><li><a href="../../内存拓展/Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller" >内存拓展</a><ul><li><a href="../../内存拓展/Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller" >Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller</a></li></ul><ul><li><a href="../../内存拓展/Accelerating_Performance_of_GPU-based_Workloads_Using_CXL" >Accelerating_Performance_of_GPU-based_Workloads_Using_CXL</a></li></ul></li></ul><ul><li><a href="../../Prefetch/Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching" >Prefetch</a><ul><li><a href="../../Prefetch/Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching" >Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching</a></li></ul></li></ul></div>
    <div class="zood"><a class="" href="https://github.com/luzhixing12345/zood" target="_blank">zood</a></div>
    <script type="text/javascript" src="../../../js/next_front.js"></script><script>addLink("../../内存拓展/Breaking_Barriers:Expanding_GPU_Memory_with_Sub-Two_Digit_Nanosecond_Latency_CXL_Controller","../../Prefetch/Polaris: Enhancing CXL-based Memory Expanders with Memory-side Prefetching","ab");</script><script type="text/javascript" src="../../../js/change_mode.js"></script><script>addChangeModeButton("../../../img/sun.png","../../../img/moon.png");</script><script type="text/javascript" src="../../../js/copy_code.js"></script><script>addCodeCopy("../../../img/clipboard.svg","../../../img/clipboard-check.svg");</script><script type="text/javascript" src="../../../js/navigator.js"></script><script type="text/javascript" src="../../../js/picture_preview.js"></script><script type="text/javascript" src="../../../js/global_js_configuration.js"></script>
</body>

</html>